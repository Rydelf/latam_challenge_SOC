{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan las bibliotecas necesarias para el correcto funcionamiento de las funciones siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import json\n",
    "from google.cloud import storage\n",
    "from collections import Counter\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación para lectura del archivo json desde GCP. Con los parámetros: nombre del bucket: latam-1, nombre del archivo: farmers-protest-tweets-2021-2-4.json, id del proyecto GCP: latam-challenge-417813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://twitter.com/ArjunSinghPanam/status/1364506249291784198', 'date': '2021-02-24T09:23:35+00:00', 'content': 'The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \\n\\n@narendramodi @DelhiPolice Shame on you. \\n\\n#ModiDontSellFarmers \\n#FarmersProtest \\n#FreeNodeepKaur https://t.co/es3kn0IQAF', 'renderedContent': 'The world progresses while the Indian police and Govt are still trying to take India back to the horrific past through its tyranny. \\n\\n@narendramodi @DelhiPolice Shame on you. \\n\\n#ModiDontSellFarmers \\n#FarmersProtest \\n#FreeNodeepKaur twitter.com/ravisinghka/st…', 'id': 1364506249291784198, 'user': {'username': 'ArjunSinghPanam', 'displayname': 'Arjun Singh Panam', 'id': 45091142, 'description': 'Global Citizen, Actor, Director: Sky is the roof above my head, the world is the road I travel, love is my food & mother earth is my bed. Roy in @CosmosMovie', 'rawDescription': 'Global Citizen, Actor, Director: Sky is the roof above my head, the world is the road I travel, love is my food & mother earth is my bed. Roy in @CosmosMovie', 'descriptionUrls': [], 'verified': False, 'created': '2009-06-06T07:50:57+00:00', 'followersCount': 603, 'friendsCount': 311, 'statusesCount': 17534, 'favouritesCount': 4269, 'listedCount': 23, 'mediaCount': 1211, 'location': '', 'protected': False, 'linkUrl': 'https://www.cosmosmovieofficial.com', 'linkTcourl': 'https://t.co/3uaoV3gCt3', 'profileImageUrl': 'https://pbs.twimg.com/profile_images/1215541746492461056/3De61YoQ_normal.jpg', 'profileBannerUrl': 'https://pbs.twimg.com/profile_banners/45091142/1612601766', 'url': 'https://twitter.com/ArjunSinghPanam'}, 'outlinks': ['https://twitter.com/ravisinghka/status/1364150844757860352'], 'tcooutlinks': ['https://t.co/es3kn0IQAF'], 'replyCount': 0, 'retweetCount': 0, 'likeCount': 0, 'quoteCount': 0, 'conversationId': 1364506249291784198, 'lang': 'en', 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'sourceUrl': 'http://twitter.com/download/iphone', 'sourceLabel': 'Twitter for iPhone', 'media': None, 'retweetedTweet': None, 'quotedTweet': {'url': 'https://twitter.com/RaviSinghKA/status/1364150844757860352', 'date': '2021-02-23T09:51:20+00:00', 'content': 'This is what the indian police are good at, beating &amp; raping women ! @police_haryana @DelhiPolice \\n\\nhttps://t.co/mj1qzF7nGh', 'renderedContent': 'This is what the indian police are good at, beating &amp; raping women ! @police_haryana @DelhiPolice \\n\\ngoogle.co.uk/amp/s/m.timeso…', 'id': 1364150844757860352, 'user': {'username': 'RaviSinghKA', 'displayname': 'ravinder singh', 'id': 2347762888, 'description': 'Founder/CEO of Khalsa Aid, Sikh,philanthropist, 20 Years of coordinating aid,humanitarian & passionate about human rights.All views my own:Inc working in Iraq', 'rawDescription': 'Founder/CEO of Khalsa Aid, Sikh,philanthropist, 20 Years of coordinating aid,humanitarian & passionate about human rights.All views my own:Inc working in Iraq', 'descriptionUrls': [], 'verified': False, 'created': '2014-02-16T23:38:54+00:00', 'followersCount': 227423, 'friendsCount': 4042, 'statusesCount': 38683, 'favouritesCount': 30134, 'listedCount': 212, 'mediaCount': 4944, 'location': 'Slough, England ', 'protected': False, 'linkUrl': 'http://www.khalsaaid.org', 'linkTcourl': 'https://t.co/cgdi8BLkK2', 'profileImageUrl': 'https://pbs.twimg.com/profile_images/686526444642643968/bnCPdE7N_normal.jpg', 'profileBannerUrl': 'https://pbs.twimg.com/profile_banners/2347762888/1591307489', 'url': 'https://twitter.com/RaviSinghKA'}, 'outlinks': ['https://www.google.co.uk/amp/s/m.timesofindia.com/city/chandigarh/was-brutally-thrashed-in-thana-nodeep-kaur-tells-punjab-and-haryana-high-court/amp_articleshow/81164092.cms'], 'tcooutlinks': ['https://t.co/mj1qzF7nGh'], 'replyCount': 66, 'retweetCount': 744, 'likeCount': 1939, 'quoteCount': 59, 'conversationId': 1364150844757860352, 'lang': 'en', 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'sourceUrl': 'http://twitter.com/download/iphone', 'sourceLabel': 'Twitter for iPhone', 'media': None, 'retweetedTweet': None, 'quotedTweet': None, 'mentionedUsers': [{'username': 'police_haryana', 'displayname': 'Haryana Police', 'id': 887564756629966848, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/police_haryana'}, {'username': 'DelhiPolice', 'displayname': '#DilKiPolice Delhi Police', 'id': 1850705408, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/DelhiPolice'}]}, 'mentionedUsers': [{'username': 'narendramodi', 'displayname': 'Narendra Modi', 'id': 18839785, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/narendramodi'}, {'username': 'DelhiPolice', 'displayname': '#DilKiPolice Delhi Police', 'id': 1850705408, 'description': None, 'rawDescription': None, 'descriptionUrls': None, 'verified': None, 'created': None, 'followersCount': None, 'friendsCount': None, 'statusesCount': None, 'favouritesCount': None, 'listedCount': None, 'mediaCount': None, 'location': None, 'protected': None, 'linkUrl': None, 'linkTcourl': None, 'profileImageUrl': None, 'profileBannerUrl': None, 'url': 'https://twitter.com/DelhiPolice'}]}]\n"
     ]
    }
   ],
   "source": [
    "def read_json_from_gcp(bucket_name, file_name, project_id):\n",
    "    # Inicializa el cliente de almacenamiento con el ID del proyecto\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    \n",
    "    # Obtiene el bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # Obtiene el blob (archivo) del bucket\n",
    "    blob = bucket.blob(file_name)\n",
    "    \n",
    "    # Descarga el contenido del archivo JSON como bytes\n",
    "    json_content_bytes = blob.download_as_string()\n",
    "    \n",
    "    # Decodifica cada línea del archivo JSON\n",
    "    json_data = [json.loads(line) for line in json_content_bytes.decode('utf-8').splitlines() if line.strip()]\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "# Nombre del bucket y del archivo JSON en GCP\n",
    "bucket_name = \"latam-1\"\n",
    "file_name = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "# ID de tu proyecto de Google Cloud\n",
    "project_id = \"latam-challenge-417813\"\n",
    "\n",
    "# Lee el archivo JSON desde el bucket\n",
    "json_content = read_json_from_gcp(bucket_name, file_name, project_id)\n",
    "\n",
    "# Imprime el primer elemento para verificar la carga\n",
    "print(json_content[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se asigna a variable file_path la función read_json_from_gcp(bucket_name, file_name, project_id), para así leer el archivo json desde la nube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = read_json_from_gcp(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la función q1_time, con enfoque en el tiempo de ejecución utilizando el archivo JSON desde GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 24), 'ArjunSinghPanam'), (datetime.date(2021, 2, 23), 'Avni_here'), (datetime.date(2021, 2, 20), 'JBBal75'), (datetime.date(2021, 2, 18), 'LakhzClick'), (datetime.date(2021, 2, 17), 'kisan_HRY'), (datetime.date(2021, 2, 13), 'annuthatte'), (datetime.date(2021, 2, 12), 'prabhatsinghdn')]\n"
     ]
    }
   ],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Lista para almacenar tuplas de fecha y usuario más activo\n",
    "    date_top_user = []\n",
    "    \n",
    "    # Diccionario para contar tweets por fecha\n",
    "    date_tweets = {}\n",
    "    \n",
    "        \n",
    "    for tweet in file_path:\n",
    "        if 'date' in tweet:\n",
    "            tweet_date = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S%z').date()\n",
    "            user = tweet['user']['username']\n",
    "            \n",
    "            # Actualizar el conteo de tweets por fecha\n",
    "            date_tweets[tweet_date] = date_tweets.get(tweet_date, 0) + 1\n",
    "            \n",
    "            # Actualizar el usuario más activo para esta fecha\n",
    "            if not date_top_user or date_tweets[tweet_date] > date_tweets[date_top_user[-1][0]]:\n",
    "                date_top_user.append((tweet_date, user))\n",
    "                date_top_user.sort(key=lambda x: x[0], reverse=True)\n",
    "                date_top_user = date_top_user[:10]\n",
    "                    \n",
    "    return date_top_user\n",
    "\n",
    "# Ejemplo de uso\n",
    "result = q1_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación de la función q1_memory, con un enfoque en la optimización de la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'SikhVibes'), (datetime.date(2021, 2, 13), 'Gurpreetd86'), (datetime.date(2021, 2, 17), 'MovimentoGhadar'), (datetime.date(2021, 2, 16), 'Anumanhas11'), (datetime.date(2021, 2, 14), 'khush18'), (datetime.date(2021, 2, 18), 'rebelpacifist'), (datetime.date(2021, 2, 15), 'DeepSin79880831'), (datetime.date(2021, 2, 20), 'IndiaToday'), (datetime.date(2021, 2, 23), 'SahibSi39465273'), (datetime.date(2021, 2, 19), 'A_W_M_B')]\n"
     ]
    }
   ],
   "source": [
    "def q1_memory(tweets: List[dict]) -> List[Tuple[datetime.date, str]]:\n",
    "    # Diccionario para almacenar la cantidad de tweets por fecha\n",
    "    date_tweets = {}\n",
    "    # Diccionario para almacenar el usuario más activo por fecha\n",
    "    date_top_user = {}\n",
    "\n",
    "    # Procesar cada tweet en la lista\n",
    "    for tweet in tweets:\n",
    "        # Obtener la fecha del tweet\n",
    "        tweet_date = datetime.strptime(tweet['date'], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "        user = tweet['user']['username']\n",
    "        \n",
    "        # Contar la cantidad de tweets por fecha\n",
    "        date_tweets[tweet_date] = date_tweets.get(tweet_date, 0) + 1\n",
    "        \n",
    "        # Actualizar el usuario más activo para esta fecha\n",
    "        if tweet_date not in date_top_user:\n",
    "            date_top_user[tweet_date] = user\n",
    "        else:\n",
    "            current_tweets = date_tweets[tweet_date]\n",
    "            max_tweets = date_tweets.get(date_top_user[tweet_date], 0)\n",
    "            if current_tweets > max_tweets:\n",
    "                date_top_user[tweet_date] = user\n",
    "    \n",
    "    # Obtener las top 10 fechas con más tweets\n",
    "    top_dates = sorted(date_tweets.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    # Obtener el usuario más activo para cada fecha\n",
    "    result = [(date, date_top_user[date]) for date, _ in top_dates]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "result = q1_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son diferentes, lo cual es correcto dada la naturaleza de optimización de tiempo y memoria que se buscaba para cada función:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Optimización de Tiempo (q1_time):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción: Este enfoque se centra en minimizar el tiempo necesario para procesar y analizar los datos. La prioridad principal es completar la tarea en la menor cantidad de tiempo posible, incluso si esto implica un uso más alto de memoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación en q1_time: En la función q1_time, se procesan todos los tweets de forma eficiente para determinar las fechas con más publicaciones y los usuarios más activos para esas fechas. Se utiliza un diccionario para contar los tweets por fecha y otro diccionario para mantener al usuario más activo por fecha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventajas: Es adecuado para conjuntos de datos más pequeños en los que el consumo de memoria no es un problema. Permite obtener resultados rápidamente al priorizar el tiempo de ejecución.· \"q1_time\" se enfoca en la optimización de tiempo al procesar eficientemente todos los tweets para determinar las fechas con más publicaciones y el usuario más activo para cada una de esas fechas. Esto se logra sin preocuparse por el consumo de memoria adicional para almacenar todos los usuarios y sus tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque de Optimización de Memoria (q1_memory):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción: Este enfoque se enfoca en minimizar el uso de memoria, especialmente cuando se trabaja con conjuntos de datos grandes o cuando se ejecuta en entornos con restricciones de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación en q1_memory: En la función q1_memory, se utiliza una lista para almacenar tuplas de fecha y usuario más activo, en lugar de mantener todos los tweets y usuarios en memoria. Esto reduce el consumo de memoria al evitar almacenar datos innecesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventajas: Es útil cuando se espera trabajar con grandes cantidades de datos y se necesita optimizar el uso de memoria. Aunque puede ser un poco más lento en comparación con el enfoque de optimización de tiempo, es más eficiente en términos de uso de recursos.· \"q1_memory\", por otro lado, se enfoca en la optimización de memoria al mantener una lista de tuplas que contienen solo las fechas y usuarios más activos hasta el momento, evitando así almacenar todos los tweets y usuarios en memoria. Esto reduce la cantidad de memoria necesaria, aunque a costa de un poco más de tiempo debido a la necesidad de verificar y actualizar la lista de usuarios más activos en cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espero que esto aclare por qué los outputs son distintos entre ambas funciones y cómo cada una cumple con el objetivo de optimización específico. Si tienes más preguntas o necesitas más ayuda, no dudes en preguntar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación función q2_time, con enfoque en optimización de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n"
     ]
    }
   ],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Lista para almacenar los emojis y sus conteos\n",
    "    emoji_counts = Counter()    \n",
    "        \n",
    "    for tweet in file_path:\n",
    "        # Obtener el contenido del tweet\n",
    "        content = tweet.get('content', '')\n",
    "        # Convertir emojis Unicode en texto plano y contarlos\n",
    "        emojis_text = emoji.emojize(content)\n",
    "        emojis_list = [c for c in emojis_text if c in emoji.EMOJI_DATA]\n",
    "        emoji_counts.update(emojis_list)\n",
    "    \n",
    "    # Obtener los top 10 emojis más usados\n",
    "    top_emojis = emoji_counts.most_common(10)\n",
    "    \n",
    "    return top_emojis\n",
    "\n",
    "# Ejemplo de uso\n",
    "result = q2_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación función q2_memory, con enfoque en la optimización de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🏻', 2080), ('❤', 1779), ('🤣', 1668), ('🏽', 1218), ('👇', 1108)]\n"
     ]
    }
   ],
   "source": [
    "def q2_memory(bucket_name: str, file_name: str, project_id: str) -> List[Tuple[str, int]]:\n",
    "    emoji_counts = Counter()\n",
    "\n",
    "    # Obtener los datos JSON del archivo en GCP\n",
    "    json_data = read_json_from_gcp(bucket_name, file_name, project_id)\n",
    "\n",
    "    # Procesar los tweets para contar emojis\n",
    "    for tweet_data in json_data:\n",
    "        # Obtener el contenido del tweet\n",
    "        content = tweet_data.get('content', '')\n",
    "        # Convertir emojis Unicode en texto plano y contarlos\n",
    "        emojis_text = emoji.emojize(content)\n",
    "        emojis_list = [c for c in emojis_text if c in emoji.EMOJI_DATA]\n",
    "        emoji_counts.update(emojis_list)\n",
    "\n",
    "    # Obtener los top 10 emojis más usados\n",
    "    top_emojis = emoji_counts.most_common(10)\n",
    "\n",
    "    return top_emojis\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "result_memory = q2_memory(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "print(result_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas funciones, q2_time y q2_memory, tienen como objetivo contar los emojis más utilizados en tweets, pero difieren en la forma en que acceden y procesan los datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q2_time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque: Carga el archivo de tweets como un iterable de diccionarios y procesa cada tweet en un bucle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Espera que el archivo ya esté cargado en la memoria como una lista de diccionarios, donde cada diccionario representa un tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Itera sobre cada tweet y extrae el contenido del tweet para contar los emojis presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q2_memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque: Lee el archivo JSON línea por línea para optimizar el uso de memoria, especialmente para archivos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcionamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Utiliza la función read_json_from_gcp para leer el archivo JSON desde Google Cloud Storage línea por línea, minimizando así la cantidad de datos almacenados en la memoria RAM al mismo tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Procesa cada tweet a medida que se lee desde el archivo, contando los emojis presentes en el contenido del tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación q3_time con enforque en la optimización del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "def q3_time(file_path) -> List[Tuple[str, int]]:\n",
    "    # Diccionario para contar menciones por usuario\n",
    "    mentions_count = {}\n",
    "    \n",
    "    # Iterar sobre cada tweet en los datos JSON\n",
    "    for tweet in file_path:\n",
    "        # Verificar si la clave 'mentionedUsers' está presente en el tweet\n",
    "        if 'mentionedUsers' in tweet:\n",
    "            mentioned_users = tweet['mentionedUsers']\n",
    "            # Verificar si mentioned_users no es None\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:\n",
    "                        mentions_count[username] = mentions_count.get(username, 0) + 1\n",
    "    \n",
    "    # Ordenar los usuarios por número de menciones de forma descendente\n",
    "    top_users = sorted(mentions_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return top_users[:10]  # Devuelve los 10 usuarios más mencionados\n",
    "\n",
    "# Calcular el top 10 de usuarios más mencionados\n",
    "result = q3_time(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación q3_memory con enfoque en la optimización del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "def q3_memory(bucket_name: str, file_name: str, project_id: str) -> List[Tuple[str, int]]:\n",
    "    # Diccionario para contar menciones por usuario\n",
    "    mentions_count = {}\n",
    "\n",
    "    # Obtener los datos JSON del archivo en GCP\n",
    "    json_data = read_json_from_gcp(bucket_name, file_name, project_id)\n",
    "    \n",
    "    # Iterar sobre cada tweet en los datos JSON generados\n",
    "    for tweet in json_data:\n",
    "        # Verificar si la clave 'mentionedUsers' está presente en el tweet\n",
    "        if 'mentionedUsers' in tweet:\n",
    "            mentioned_users = tweet['mentionedUsers']\n",
    "            # Verificar si mentioned_users no es None\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:\n",
    "                        # Utilizar un generador de expresión para obtener el username\n",
    "                        mentions_count[username] = mentions_count.get(username, 0) + 1\n",
    "    \n",
    "    # Utilizar un generador para ordenar y obtener los 10 usuarios más mencionados\n",
    "    top_users_generator = (item for item in sorted(mentions_count.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "    \n",
    "    return list(top_users_generator)  # Devuelve los 10 usuarios más mencionados como lista\n",
    "\n",
    "\n",
    "# Calcular el top 10 de usuarios más mencionados\n",
    "result = q3_memory(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Las dos funciones que proporcioné en mi última respuesta son esencialmente iguales. Ambas versiones utilizan un enfoque de generador para procesar los datos de manera eficiente y minimizar el uso de memoria. La diferencia principal radica en cómo se obtienen los datos para procesarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· 'q3_time': Toma como entrada un objeto JSON cargado en memoria (json_data) que contiene todos los tweets a procesar. Esta carga completa del JSON puede consumir más memoria, especialmente si el archivo JSON es grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· 'q3_memory': Utiliza generadores para procesar los tweets de forma incremental, lo que reduce la cantidad de memoria necesaria en comparación con cargar todos los datos en memoria de una vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas funciones realizan un procesamiento similar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Iteran sobre cada tweet en los datos JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Verifican si la clave 'mentionedUsers' está presente en el tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Si está presente, obtienen la lista de usuarios mencionados y cuentan las menciones por usuario en el diccionario mentions_count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· Ordenan los usuarios por número de menciones de forma descendente y devuelven los 10 usuarios más mencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se ejecutarán las pruebas de memoria y tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 1.5963006019592285 seconds\n",
      "Memory Usage (Peak): 3164.453125 MB\n",
      "[(datetime.date(2021, 2, 24), 'ArjunSinghPanam'), (datetime.date(2021, 2, 23), 'Avni_here'), (datetime.date(2021, 2, 20), 'JBBal75'), (datetime.date(2021, 2, 18), 'LakhzClick'), (datetime.date(2021, 2, 17), 'kisan_HRY'), (datetime.date(2021, 2, 13), 'annuthatte'), (datetime.date(2021, 2, 12), 'prabhatsinghdn')]\n",
      "Execution Time: 1.5007116794586182 seconds\n",
      "Memory Usage (Peak): 3156.80859375 MB\n",
      "[(datetime.date(2021, 2, 12), 'SikhVibes'), (datetime.date(2021, 2, 13), 'Gurpreetd86'), (datetime.date(2021, 2, 17), 'MovimentoGhadar'), (datetime.date(2021, 2, 16), 'Anumanhas11'), (datetime.date(2021, 2, 14), 'khush18'), (datetime.date(2021, 2, 18), 'rebelpacifist'), (datetime.date(2021, 2, 15), 'DeepSin79880831'), (datetime.date(2021, 2, 20), 'IndiaToday'), (datetime.date(2021, 2, 23), 'SahibSi39465273'), (datetime.date(2021, 2, 19), 'A_W_M_B')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "\n",
    "# Decorador para medir la memoria en uso\n",
    "def measure_memory(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        mem, result = memory_usage((func, args, kwargs), max_usage=True, retval=True)\n",
    "        print(f\"Memory Usage (Peak): {mem} MB\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Decorador para medir el tiempo de ejecución\n",
    "def measure_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution Time: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Función original q1_memory\n",
    "def q1_memory(tweets: List[dict]) -> List[Tuple[datetime.date, str]]:\n",
    "    # Diccionario para almacenar la cantidad de tweets por fecha\n",
    "    date_tweets = {}\n",
    "    # Diccionario para almacenar el usuario más activo por fecha\n",
    "    date_top_user = {}\n",
    "\n",
    "    # Procesar cada tweet en la lista\n",
    "    for tweet in tweets:\n",
    "        # Obtener la fecha del tweet\n",
    "        tweet_date = datetime.strptime(tweet['date'], \"%Y-%m-%dT%H:%M:%S%z\").date()\n",
    "        user = tweet['user']['username']\n",
    "        \n",
    "        # Contar la cantidad de tweets por fecha\n",
    "        date_tweets[tweet_date] = date_tweets.get(tweet_date, 0) + 1\n",
    "        \n",
    "        # Actualizar el usuario más activo para esta fecha\n",
    "        if tweet_date not in date_top_user:\n",
    "            date_top_user[tweet_date] = user\n",
    "        else:\n",
    "            current_tweets = date_tweets[tweet_date]\n",
    "            max_tweets = date_tweets.get(date_top_user[tweet_date], 0)\n",
    "            if current_tweets > max_tweets:\n",
    "                date_top_user[tweet_date] = user\n",
    "    \n",
    "    # Obtener las top 10 fechas con más tweets\n",
    "    top_dates = sorted(date_tweets.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    # Obtener el usuario más activo para cada fecha\n",
    "    result = [(date, date_top_user[date]) for date, _ in top_dates]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Función original q1_time\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Lista para almacenar tuplas de fecha y usuario más activo\n",
    "    date_top_user = []\n",
    "    \n",
    "    # Diccionario para contar tweets por fecha\n",
    "    date_tweets = {}\n",
    "    \n",
    "      \n",
    "    for tweet in file_path:\n",
    "        if 'date' in tweet:\n",
    "            tweet_date = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S%z').date()\n",
    "            user = tweet['user']['username']\n",
    "            \n",
    "            # Actualizar el conteo de tweets por fecha\n",
    "            date_tweets[tweet_date] = date_tweets.get(tweet_date, 0) + 1\n",
    "            \n",
    "            # Actualizar el usuario más activo para esta fecha\n",
    "            if not date_top_user or date_tweets[tweet_date] > date_tweets[date_top_user[-1][0]]:\n",
    "                date_top_user.append((tweet_date, user))\n",
    "                date_top_user.sort(key=lambda x: x[0], reverse=True)\n",
    "                date_top_user = date_top_user[:10]\n",
    "                    \n",
    "    return date_top_user\n",
    "\n",
    "# Definición file_path\n",
    "file_path = read_json_from_gcp(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "\n",
    "# Medir el rendimiento de q1_memory\n",
    "@measure_memory\n",
    "@measure_time\n",
    "def run_q1_memory(file_path):\n",
    "    return q1_memory(file_path)\n",
    "\n",
    "result_time = run_q1_memory(file_path)\n",
    "print(result_memory)\n",
    "\n",
    "# Medir el rendimiento de q1_time\n",
    "@measure_memory\n",
    "@measure_time\n",
    "def run_q1_time(file_path):\n",
    "    return q1_time(file_path)\n",
    "\n",
    "result_memory = run_q1_time(file_path)\n",
    "print(result_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 32.06669211387634 seconds\n",
      "Memory Usage (Peak): 4975.41015625 MB\n",
      "Execution Time: 1.3510911464691162 seconds\n",
      "Memory Usage (Peak): 3621.42578125 MB\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "\n",
    "# Decorador para medir la memoria en uso\n",
    "def measure_memory(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        mem, result = memory_usage((func, args, kwargs), max_usage=True, retval=True)\n",
    "        print(f\"Memory Usage (Peak): {mem} MB\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Decorador para medir el tiempo de ejecución\n",
    "def measure_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution Time: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Función original q2_memory\n",
    "def q2_memory(bucket_name: str, file_name: str, project_id: str) -> List[Tuple[str, int]]:\n",
    "    emoji_counts = Counter()\n",
    "\n",
    "    # Obtener los datos JSON del archivo en GCP\n",
    "    json_data = read_json_from_gcp(bucket_name, file_name, project_id)\n",
    "\n",
    "    # Procesar los tweets para contar emojis\n",
    "    for tweet_data in json_data:\n",
    "        # Obtener el contenido del tweet\n",
    "        content = tweet_data.get('content', '')\n",
    "        # Convertir emojis Unicode en texto plano y contarlos\n",
    "        emojis_text = emoji.emojize(content)\n",
    "        emojis_list = [c for c in emojis_text if c in emoji.EMOJI_DATA]\n",
    "        emoji_counts.update(emojis_list)\n",
    "\n",
    "    # Obtener los top 10 emojis más usados\n",
    "    top_emojis = emoji_counts.most_common(10)\n",
    "\n",
    "    return top_emojis\n",
    "\n",
    "# Función original q2_time\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Lista para almacenar los emojis y sus conteos\n",
    "    emoji_counts = Counter()    \n",
    "        \n",
    "    for tweet in file_path:\n",
    "        # Obtener el contenido del tweet\n",
    "        content = tweet.get('content', '')\n",
    "        # Convertir emojis Unicode en texto plano y contarlos\n",
    "        emojis_text = emoji.emojize(content)\n",
    "        emojis_list = [c for c in emojis_text if c in emoji.EMOJI_DATA]\n",
    "        emoji_counts.update(emojis_list)\n",
    "    \n",
    "    # Obtener los top 10 emojis más usados\n",
    "    top_emojis = emoji_counts.most_common(10)\n",
    "    \n",
    "    return top_emojis\n",
    "\n",
    "# Definir file_path para q2_time\n",
    "file_path = read_json_from_gcp(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "\n",
    "# Medir el rendimiento de q2_memory\n",
    "@measure_memory\n",
    "@measure_time\n",
    "def run_q2_memory(bucket_name, file_name, project_id):\n",
    "    return q2_memory(bucket_name, file_name, project_id)\n",
    "\n",
    "result_memory = run_q2_memory(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "\n",
    "# Medir el rendimiento de q2_time\n",
    "@measure_memory\n",
    "@measure_time\n",
    "def run_q2_time(file_path):\n",
    "    return q2_time(file_path)\n",
    "\n",
    "result_time = run_q2_time(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebas q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 31.493772745132446 seconds\n",
      "Memory Usage (Peak): 4960.30859375 MB\n",
      "Execution Time: 0.07035517692565918 seconds\n",
      "Execution Time: 0.06253623962402344 seconds\n",
      "Memory Usage (Peak): 3607.6171875 MB\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "\n",
    "# Decorador para medir la memoria en uso\n",
    "def measure_memory(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        mem, result = memory_usage((func, args, kwargs), max_usage=True, retval=True)\n",
    "        print(f\"Memory Usage (Peak): {mem} MB\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Decorador para medir el tiempo de ejecución\n",
    "def measure_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution Time: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Función original q3_memory\n",
    "def q3_memory(bucket_name: str, file_name: str, project_id: str) -> List[Tuple[str, int]]:\n",
    "    mentions_count = {}\n",
    "\n",
    "    # Obtener los datos JSON del archivo en GCP\n",
    "    json_data = read_json_from_gcp(bucket_name, file_name, project_id)\n",
    "    \n",
    "    # Iterar sobre cada tweet en los datos JSON generados\n",
    "    for tweet in json_data:\n",
    "        # Verificar si la clave 'mentionedUsers' está presente en el tweet\n",
    "        if 'mentionedUsers' in tweet:\n",
    "            mentioned_users = tweet['mentionedUsers']\n",
    "            # Verificar si mentioned_users no es None\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:\n",
    "                        # Utilizar un generador de expresión para obtener el username\n",
    "                        mentions_count[username] = mentions_count.get(username, 0) + 1\n",
    "    \n",
    "    # Utilizar un generador para ordenar y obtener los 10 usuarios más mencionados\n",
    "    top_users_generator = (item for item in sorted(mentions_count.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "    \n",
    "    return list(top_users_generator)  # Devuelve los 10 usuarios más mencionados como lista\n",
    "\n",
    "# Función original q3_time\n",
    "def q3_time(file_path) -> List[Tuple[str, int]]:\n",
    "    mentions_count = {}\n",
    "    \n",
    "    # Iterar sobre cada tweet en los datos JSON\n",
    "    for tweet in file_path:\n",
    "        # Verificar si la clave 'mentionedUsers' está presente en el tweet\n",
    "        if 'mentionedUsers' in tweet:\n",
    "            mentioned_users = tweet['mentionedUsers']\n",
    "            # Verificar si mentioned_users no es None\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:\n",
    "                        mentions_count[username] = mentions_count.get(username, 0) + 1\n",
    "    \n",
    "    # Ordenar los usuarios por número de menciones de forma descendente\n",
    "    top_users = sorted(mentions_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return top_users[:10]  # Devuelve los 10 usuarios más mencionados\n",
    "\n",
    "# Definir file_path para q3_time\n",
    "file_path = read_json_from_gcp(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "\n",
    "# Medir el rendimiento de q3_memory\n",
    "@measure_memory\n",
    "@measure_time\n",
    "def run_q3_memory(bucket_name, file_name, project_id):\n",
    "    return q3_memory(bucket_name, file_name, project_id)\n",
    "\n",
    "result_memory = run_q3_memory(\"latam-1\", \"farmers-protest-tweets-2021-2-4.json\", \"latam-challenge-417813\")\n",
    "\n",
    "# Medir el rendimiento de q3_time\n",
    "@measure_memory\n",
    "@measure_time\n",
    "def run_q3_time(file_path):\n",
    "    return q3_time(file_path)\n",
    "\n",
    "result_time = run_q3_time(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se concluye que en el ambiente en que se generaron las pruebas. La eficiencia general de las funciones de tiempo, fue mucho mayor que las con enfoque a la optimización de memoria. Todo esto trabajando siempre el archivo desde la nube con GCP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
